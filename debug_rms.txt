============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.4.1, pluggy-1.6.0
rootdir: /home/adespirl/git/wave
configfile: setup.cfg
collected 1 item

tests/kernel/wave/rmsnorm_test.py ***Before set_thread_dependent_index_from_reduce***

region_0 [root]:

graph():
    %a :  [num_users=1] = placeholder[target=a]
    %gamma :  [num_users=0] = placeholder[target=gamma]
    %c :  [num_users=1] = placeholder[target=c]
    %register :  [num_users=1] = [register](args = ((M,), f16, EMB_SIZE), kwargs = {})
    %read :  [num_users=2] = [read](args = (%a, ELEMS_PER_THREAD, None, (), None, None), kwargs = {})
    %mul :  [num_users=1] = [mul](args = (%read, %read), kwargs = {})
    %sum_1 :  [num_users=1] = [sum](args = (%mul, None, N, True), kwargs = {})
    %truediv :  [num_users=1] = [truediv](args = (%sum_1, %register), kwargs = {})
    %sqrt :  [num_users=1] = [sqrt](args = (%truediv,), kwargs = {})
    %broadcast :  [num_users=1] = [broadcast](args = (%sqrt, [M, N]), kwargs = {})
    %truediv_1 :  [num_users=1] = [truediv](args = (%read, %broadcast), kwargs = {})
    %write :  [num_users=0] = [write](args = (%truediv_1, %c, None, None, (), None), kwargs = {})
    return None
Custom format:
placeholder(_name=a, _type=Memory[M, N].of(f16)) type(Memory[M, N].of(f16))
placeholder(_name=gamma, _type=Memory[N].of(f16)) type(Memory[N].of(f16))
placeholder(_name=c, _type=Memory[M, N].of(f16)) type(Memory[M, N].of(f16))
register(shape=(M,), dtype=f16, value=EMB_SIZE, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
read(memory=a, elements_per_thread=ELEMS_PER_THREAD, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 : 1 : 1}) type(Register[M, N].of(f16))
mul(lhs=read, rhs=read, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 : 1 : 1}) type(Register[M, N].of(f16))
sum(arg=mul, dim=N, block=True, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
truediv(lhs=sum_1, rhs=register, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
sqrt(arg=truediv, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
broadcast(arg=sqrt, target_shape=[M, N], index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 : 1 : 1}) type(Register[M, N].of(f16))
truediv(lhs=read, rhs=broadcast, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 : 1 : 1}) type(Register[M, N].of(f16))
write(register_=truediv_1, memory=c, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 : 1 : 1}) type(Memory[M, N].of(f16))
output(return_vals=(None,)) type(None)
***After set_thread_dependent_index_from_reduce***

region_0 [root]:

graph():
    %a :  [num_users=1] = placeholder[target=a]
    %gamma :  [num_users=0] = placeholder[target=gamma]
    %c :  [num_users=1] = placeholder[target=c]
    %register :  [num_users=1] = [register](args = ((M,), f16, EMB_SIZE), kwargs = {})
    %read :  [num_users=2] = [read](args = (%a, ELEMS_PER_THREAD, None, (), None, None), kwargs = {})
    %mul :  [num_users=1] = [mul](args = (%read, %read), kwargs = {})
    %sum_1 :  [num_users=1] = [sum](args = (%mul, None, N, True), kwargs = {})
    %truediv :  [num_users=1] = [truediv](args = (%sum_1, %register), kwargs = {})
    %sqrt :  [num_users=1] = [sqrt](args = (%truediv,), kwargs = {})
    %broadcast :  [num_users=1] = [broadcast](args = (%sqrt, [M, N]), kwargs = {})
    %truediv_1 :  [num_users=1] = [truediv](args = (%read, %broadcast), kwargs = {})
    %write :  [num_users=0] = [write](args = (%truediv_1, %c, None, None, (), None), kwargs = {})
    return None
Custom format:
placeholder(_name=a, _type=Memory[M, N].of(f16)) type(Memory[M, N].of(f16))
placeholder(_name=gamma, _type=Memory[N].of(f16)) type(Memory[N].of(f16))
placeholder(_name=c, _type=Memory[M, N].of(f16)) type(Memory[M, N].of(f16))
register(shape=(M,), dtype=f16, value=EMB_SIZE, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
read(memory=a, elements_per_thread=ELEMS_PER_THREAD, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
mul(lhs=read, rhs=read, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
sum(arg=mul, dim=N, block=True, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
truediv(lhs=sum_1, rhs=register, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
sqrt(arg=truediv, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
broadcast(arg=sqrt, target_shape=[M, N], index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
truediv(lhs=read, rhs=broadcast, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
write(register_=truediv_1, memory=c, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Memory[M, N].of(f16))
output(return_vals=(None,)) type(None)
***After expand_graph***

region_0 [root]:

graph():
    %a :  [num_users=5] = placeholder[target=a]
    %gamma :  [num_users=0] = placeholder[target=gamma]
    %c :  [num_users=5] = placeholder[target=c]
    %register_M:0_N:0 :  [num_users=1] = [register](args = ((M,), f16, EMB_SIZE), kwargs = {})
    %read_M:0_N:0 :  [num_users=2] = [read](args = (%a, ELEMS_PER_THREAD, None, (), None, None), kwargs = {})
    %read_M:0_N:1 :  [num_users=2] = [read](args = (%a, ELEMS_PER_THREAD, None, (), None, None), kwargs = {})
    %read_M:0_N:2 :  [num_users=2] = [read](args = (%a, ELEMS_PER_THREAD, None, (), None, None), kwargs = {})
    %read_M:0_N:3 :  [num_users=2] = [read](args = (%a, ELEMS_PER_THREAD, None, (), None, None), kwargs = {})
    %read_M:0_N:4 :  [num_users=2] = [read](args = (%a, ELEMS_PER_THREAD, None, (), None, None), kwargs = {})
    %mul_M:0_N:0 :  [num_users=1] = [mul](args = (%read_M:0_N:0, %read_M:0_N:0), kwargs = {})
    %mul_M:0_N:1 :  [num_users=1] = [mul](args = (%read_M:0_N:1, %read_M:0_N:1), kwargs = {})
    %mul_M:0_N:2 :  [num_users=1] = [mul](args = (%read_M:0_N:2, %read_M:0_N:2), kwargs = {})
    %mul_M:0_N:3 :  [num_users=1] = [mul](args = (%read_M:0_N:3, %read_M:0_N:3), kwargs = {})
    %mul_M:0_N:4 :  [num_users=1] = [mul](args = (%read_M:0_N:4, %read_M:0_N:4), kwargs = {})
    %sum_1_M:0_N:0 :  [num_users=1] = [sum](args = ([%mul_M:0_N:0, %mul_M:0_N:1, %mul_M:0_N:2, %mul_M:0_N:3, %mul_M:0_N:4], None, N, True), kwargs = {})
    %truediv_M:0_N:0 :  [num_users=1] = [truediv](args = (%sum_1_M:0_N:0, %register_M:0_N:0), kwargs = {})
    %sqrt_M:0_N:0 :  [num_users=5] = [sqrt](args = (%truediv_M:0_N:0,), kwargs = {})
    %broadcast_M:0_N:0 :  [num_users=1] = [broadcast](args = (%sqrt_M:0_N:0, [M, N]), kwargs = {})
    %broadcast_M:0_N:1 :  [num_users=1] = [broadcast](args = (%sqrt_M:0_N:0, [M, N]), kwargs = {})
    %broadcast_M:0_N:2 :  [num_users=1] = [broadcast](args = (%sqrt_M:0_N:0, [M, N]), kwargs = {})
    %broadcast_M:0_N:3 :  [num_users=1] = [broadcast](args = (%sqrt_M:0_N:0, [M, N]), kwargs = {})
    %broadcast_M:0_N:4 :  [num_users=1] = [broadcast](args = (%sqrt_M:0_N:0, [M, N]), kwargs = {})
    %truediv_1_M:0_N:0 :  [num_users=1] = [truediv](args = (%read_M:0_N:0, %broadcast_M:0_N:0), kwargs = {})
    %truediv_1_M:0_N:1 :  [num_users=1] = [truediv](args = (%read_M:0_N:1, %broadcast_M:0_N:1), kwargs = {})
    %truediv_1_M:0_N:2 :  [num_users=1] = [truediv](args = (%read_M:0_N:2, %broadcast_M:0_N:2), kwargs = {})
    %truediv_1_M:0_N:3 :  [num_users=1] = [truediv](args = (%read_M:0_N:3, %broadcast_M:0_N:3), kwargs = {})
    %truediv_1_M:0_N:4 :  [num_users=1] = [truediv](args = (%read_M:0_N:4, %broadcast_M:0_N:4), kwargs = {})
    %write_M:0_N:0 :  [num_users=0] = [write](args = (%truediv_1_M:0_N:0, %c, 4, None, (), None), kwargs = {})
    %write_M:0_N:1 :  [num_users=0] = [write](args = (%truediv_1_M:0_N:1, %c, 4, None, (), None), kwargs = {})
    %write_M:0_N:2 :  [num_users=0] = [write](args = (%truediv_1_M:0_N:2, %c, 4, None, (), None), kwargs = {})
    %write_M:0_N:3 :  [num_users=0] = [write](args = (%truediv_1_M:0_N:3, %c, 4, None, (), None), kwargs = {})
    %write_M:0_N:4 :  [num_users=0] = [write](args = (%truediv_1_M:0_N:4, %c, 4, None, (), None), kwargs = {})
    return None
Custom format:
placeholder(_name=a, _type=Memory[M, N].of(f16)) type(Memory[M, N].of(f16))
placeholder(_name=gamma, _type=Memory[N].of(f16)) type(Memory[N].of(f16))
placeholder(_name=c, _type=Memory[M, N].of(f16)) type(Memory[M, N].of(f16))
register(shape=(M,), dtype=f16, value=EMB_SIZE, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
read(memory=a, elements_per_thread=ELEMS_PER_THREAD, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
read(memory=a, elements_per_thread=ELEMS_PER_THREAD, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
read(memory=a, elements_per_thread=ELEMS_PER_THREAD, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
read(memory=a, elements_per_thread=ELEMS_PER_THREAD, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
read(memory=a, elements_per_thread=ELEMS_PER_THREAD, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
mul(lhs=read_M:0_N:0, rhs=read_M:0_N:0, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
mul(lhs=read_M:0_N:1, rhs=read_M:0_N:1, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
mul(lhs=read_M:0_N:2, rhs=read_M:0_N:2, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
mul(lhs=read_M:0_N:3, rhs=read_M:0_N:3, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
mul(lhs=read_M:0_N:4, rhs=read_M:0_N:4, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
sum(arg=[mul_M:0_N:0, mul_M:0_N:1, mul_M:0_N:2, mul_M:0_N:3, mul_M:0_N:4], dim=N, block=True, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
truediv(lhs=sum_1_M:0_N:0, rhs=register_M:0_N:0, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
sqrt(arg=truediv_M:0_N:0, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1}) type(Register[M].of(f16))
broadcast(arg=sqrt_M:0_N:0, target_shape=[M, N], index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
broadcast(arg=sqrt_M:0_N:0, target_shape=[M, N], index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
broadcast(arg=sqrt_M:0_N:0, target_shape=[M, N], index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
broadcast(arg=sqrt_M:0_N:0, target_shape=[M, N], index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
broadcast(arg=sqrt_M:0_N:0, target_shape=[M, N], index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
truediv(lhs=read_M:0_N:0, rhs=broadcast_M:0_N:0, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
truediv(lhs=read_M:0_N:1, rhs=broadcast_M:0_N:1, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
truediv(lhs=read_M:0_N:2, rhs=broadcast_M:0_N:2, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
truediv(lhs=read_M:0_N:3, rhs=broadcast_M:0_N:3, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
truediv(lhs=read_M:0_N:4, rhs=broadcast_M:0_N:4, index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Register[M, N].of(f16))
write(register_=truediv_1_M:0_N:0, memory=c, elements_per_thread=4, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Memory[M, N].of(f16))
write(register_=truediv_1_M:0_N:1, memory=c, elements_per_thread=4, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Memory[M, N].of(f16))
write(register_=truediv_1_M:0_N:2, memory=c, elements_per_thread=4, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Memory[M, N].of(f16))
write(register_=truediv_1_M:0_N:3, memory=c, elements_per_thread=4, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Memory[M, N].of(f16))
write(register_=truediv_1_M:0_N:4, memory=c, elements_per_thread=4, mapping_dynamic_vals=(), index={M: $T1*TOKENS_PER_WK + $WG1*TOKENS_PER_WK : 1 : 1, N: $WG0*N + N*floor($T0/64)/4 + 4*(Mod($T0, 64)) : 4 : 1}) type(Memory[M, N].of(f16))
output(return_vals=(None,)) type(None)
#map = affine_map<()[s0] -> (s0 * 4 + (s0 floordiv 64) * 1024)>
#map1 = affine_map<()[s0] -> (s0 * 4 + (s0 floordiv 64) * 1024 + 256)>
#map2 = affine_map<()[s0] -> (s0 * 4 + (s0 floordiv 64) * 1024 + 512)>
#map3 = affine_map<()[s0] -> (s0 * 4 + (s0 floordiv 64) * 1024 + 768)>
#map4 = affine_map<()[s0] -> (s0 * 4 + (s0 floordiv 64) * 1024 + 1024)>
#map5 = affine_map<()[s0] -> (s0 mod 64)>
#map6 = affine_map<()[s0] -> ((s0 floordiv 64) mod 4)>
#translation = #iree_codegen.translation_info<pipeline = None workgroup_size = [256, 1, 1] subgroup_size = 64>
module attributes {transform.with_named_sequence} {
  stream.executable private @test {
    stream.executable.export public @test workgroups() -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %c1, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @test(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding) attributes {translation_info = #translation} {
        %cst = arith.constant 5.120000e+03 : f16
        %c0_i32 = arith.constant 0 : i32
        %c32_i32 = arith.constant 32 : i32
        %c16_i32 = arith.constant 16 : i32
        %c8_i32 = arith.constant 8 : i32
        %c4_i32 = arith.constant 4 : i32
        %c2_i32 = arith.constant 2 : i32
        %c64_i32 = arith.constant 64 : i32
        %c1_i32 = arith.constant 1 : i32
        %c0 = arith.constant 0 : index
        %thread_id_x = gpu.thread_id  x upper_bound 256
        %alloc = memref.alloc() : memref<8xi8, #gpu.address_space<workgroup>>
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> memref<1x5120xf16, strided<[5120, 1], offset: ?>>
        %1 = affine.apply #map()[%thread_id_x]
        %2 = vector.load %0[%c0, %1] : memref<1x5120xf16, strided<[5120, 1], offset: ?>>, vector<4xf16>
        %3 = affine.apply #map1()[%thread_id_x]
        %4 = vector.load %0[%c0, %3] : memref<1x5120xf16, strided<[5120, 1], offset: ?>>, vector<4xf16>
        %5 = affine.apply #map2()[%thread_id_x]
        %6 = vector.load %0[%c0, %5] : memref<1x5120xf16, strided<[5120, 1], offset: ?>>, vector<4xf16>
        %7 = affine.apply #map3()[%thread_id_x]
        %8 = vector.load %0[%c0, %7] : memref<1x5120xf16, strided<[5120, 1], offset: ?>>, vector<4xf16>
        %9 = affine.apply #map4()[%thread_id_x]
        %10 = vector.load %0[%c0, %9] : memref<1x5120xf16, strided<[5120, 1], offset: ?>>, vector<4xf16>
        %11 = arith.mulf %2, %2 : vector<4xf16>
        %12 = arith.mulf %4, %4 : vector<4xf16>
        %13 = arith.mulf %6, %6 : vector<4xf16>
        %14 = arith.mulf %8, %8 : vector<4xf16>
        %15 = arith.mulf %10, %10 : vector<4xf16>
        %16 = arith.addf %11, %12 : vector<4xf16>
        %17 = arith.addf %16, %13 : vector<4xf16>
        %18 = arith.addf %17, %14 : vector<4xf16>
        %19 = arith.addf %18, %15 : vector<4xf16>
        %20 = vector.extract %19[0] : f16 from vector<4xf16>
        %21 = vector.extract %19[1] : f16 from vector<4xf16>
        %22 = arith.addf %20, %21 : f16
        %23 = vector.extract %19[2] : f16 from vector<4xf16>
        %24 = arith.addf %22, %23 : f16
        %25 = vector.extract %19[3] : f16 from vector<4xf16>
        %26 = arith.addf %24, %25 : f16
        %27 = vector.broadcast %26 : f16 to vector<1xf16>
        %shuffleResult, %valid = gpu.shuffle  xor %27, %c1_i32, %c64_i32 : vector<1xf16>
        %28 = arith.addf %27, %shuffleResult : vector<1xf16>
        %shuffleResult_0, %valid_1 = gpu.shuffle  xor %28, %c2_i32, %c64_i32 : vector<1xf16>
        %29 = arith.addf %28, %shuffleResult_0 : vector<1xf16>
        %shuffleResult_2, %valid_3 = gpu.shuffle  xor %29, %c4_i32, %c64_i32 : vector<1xf16>
        %30 = arith.addf %29, %shuffleResult_2 : vector<1xf16>
        %shuffleResult_4, %valid_5 = gpu.shuffle  xor %30, %c8_i32, %c64_i32 : vector<1xf16>
        %31 = arith.addf %30, %shuffleResult_4 : vector<1xf16>
        %shuffleResult_6, %valid_7 = gpu.shuffle  xor %31, %c16_i32, %c64_i32 : vector<1xf16>
        %32 = arith.addf %31, %shuffleResult_6 : vector<1xf16>
        %shuffleResult_8, %valid_9 = gpu.shuffle  xor %32, %c32_i32, %c64_i32 : vector<1xf16>
        %33 = arith.addf %32, %shuffleResult_8 : vector<1xf16>
        %view = memref.view %alloc[%c0][] : memref<8xi8, #gpu.address_space<workgroup>> to memref<4xf16, #gpu.address_space<workgroup>>
        %34 = affine.apply #map5()[%thread_id_x]
        %35 = arith.index_cast %34 : index to i32
        %36 = arith.cmpi eq, %35, %c0_i32 : i32
        scf.if %36 {
          %54 = affine.apply #map6()[%thread_id_x]
          vector.store %33, %view[%54] : memref<4xf16, #gpu.address_space<workgroup>>, vector<1xf16>
        }
        amdgpu.lds_barrier
        %37 = vector.load %view[%c0] : memref<4xf16, #gpu.address_space<workgroup>>, vector<4xf16>
        %38 = vector.extract %37[0] : f16 from vector<4xf16>
        %39 = vector.extract %37[1] : f16 from vector<4xf16>
        %40 = arith.addf %38, %39 : f16
        %41 = vector.extract %37[2] : f16 from vector<4xf16>
        %42 = arith.addf %40, %41 : f16
        %43 = vector.extract %37[3] : f16 from vector<4xf16>
        %44 = arith.addf %42, %43 : f16
        %45 = arith.divf %44, %cst : f16
        %46 = math.sqrt %45 : f16
        %47 = vector.broadcast %46 : f16 to vector<4xf16>
        %48 = arith.divf %2, %47 : vector<4xf16>
        %49 = arith.divf %4, %47 : vector<4xf16>
        %50 = arith.divf %6, %47 : vector<4xf16>
        %51 = arith.divf %8, %47 : vector<4xf16>
        %52 = arith.divf %10, %47 : vector<4xf16>
        %53 = stream.binding.subspan %arg2[%c0] : !stream.binding -> memref<1x5120xf16, strided<[5120, 1], offset: ?>>
        vector.store %48, %53[%c0, %1] : memref<1x5120xf16, strided<[5120, 1], offset: ?>>, vector<4xf16>
        vector.store %49, %53[%c0, %3] : memref<1x5120xf16, strided<[5120, 1], offset: ?>>, vector<4xf16>
        vector.store %50, %53[%c0, %5] : memref<1x5120xf16, strided<[5120, 1], offset: ?>>, vector<4xf16>
        vector.store %51, %53[%c0, %7] : memref<1x5120xf16, strided<[5120, 1], offset: ?>>, vector<4xf16>
        vector.store %52, %53[%c0, %9] : memref<1x5120xf16, strided<[5120, 1], offset: ?>>, vector<4xf16>
        return
      }
    }
  }
  func.func @isolated_benchmark$async(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view, %arg2: !hal.buffer_view, %arg3: !hal.fence, %arg4: !hal.fence) -> !hal.buffer_view {
    %0 = hal.tensor.import wait(%arg3) => %arg0 : !hal.buffer_view -> tensor<1x5120xf16>
    %1 = hal.tensor.import wait(%arg3) => %arg1 : !hal.buffer_view -> tensor<5120xf16>
    %2 = hal.tensor.import wait(%arg3) => %arg2 : !hal.buffer_view -> tensor<1x5120xf16>
    %3 = flow.dispatch @test::@test(%0, %1, %2) : (tensor<1x5120xf16>, tensor<5120xf16>, tensor<1x5120xf16>) -> %2
    %4 = hal.tensor.barrier join(%3 : tensor<1x5120xf16>) => %arg4 : !hal.fence
    %5 = hal.tensor.export %4 : tensor<1x5120xf16> -> !hal.buffer_view
    return %5 : !hal.buffer_view
  }
}

tensor([[-1.0332, -0.4841,  2.1660,  ..., -0.6167, -0.3501,  2.2285]],
       dtype=torch.float16)
tensor([[-1.0244, -0.4800,  2.1465,  ..., -0.6113, -0.3472,  2.2090]],
       dtype=torch.float16)
F

=================================== FAILURES ===================================
_____________________________ test_rmsnorm[shape0] _____________________________

shape = (1, 5120)

    @pytest.mark.parametrize(
        "shape",
        [
            (1, 5120),
        ],
    )
    @require_e2e
    def test_rmsnorm(shape):
        M = tkl.sym.M
        N = tkl.sym.N
        BLOCK_M = tkl.sym.BLOCK_M
        BLOCK_N = tkl.sym.BLOCK_N
        ELEMS_PER_THREAD = tkl.sym.ELEMS_PER_THREAD
        ADDRESS_SPACE = tkl.sym.ADDRESS_SPACE
        EMB_SIZE = tkl.sym.EMB_SIZE
        TOKENS_PER_WK = tkl.sym.TOKENS_PER_WK

        num_waves = 4
        wave_size = 64
        BLOCK_N = N
        BLOCK_M = TOKENS_PER_WK

        constraints: list[tkw.Constraint] = [
            tkw.HardwareConstraint(
                threads_per_wave=64,
                vector_shapes={M: 1, N: ELEMS_PER_THREAD * wave_size},
            )
        ]
        constraints += [tkw.WorkgroupConstraint(M, BLOCK_M, 1)]
        constraints += [tkw.WaveConstraint(M, BLOCK_M)]
        constraints += [tkw.WorkgroupConstraint(N, BLOCK_N, 0)]
        constraints += [tkw.WaveConstraint(N, BLOCK_N / num_waves)]

        @tkw.wave(constraints)
        def test(
            a: tkl.Memory[M, N, ADDRESS_SPACE, tkl.f16],
            gamma: tkl.Memory[N, ADDRESS_SPACE, tkl.f16],
            c: tkl.Memory[M, N, ADDRESS_SPACE, tkl.f16],
        ):
            length_embedding = tkl.Register[M, tkl.f16](EMB_SIZE)
            lhs = tkw.read(a, elements_per_thread=ELEMS_PER_THREAD)
            lhs_pow = lhs * lhs
            red = tkw.sum(lhs_pow, dim=N, block=True)
            result = red / length_embedding
            rms = tkw.sqrt(result)
            rms_broad = tkw.broadcast(rms, [M, N])
            a_scaled = lhs / rms_broad
            # gamma_reg = tkw.read(gamma, elements_per_thread=ELEMS_PER_THREAD)
            # gamma_broad = tkw.broadcast(gamma_reg, [M, N])
            # output = a_scaled * gamma_broad
            tkw.write(a_scaled, c)

        options = WaveCompileOptions(
            subs={
                M: shape[0],
                N: shape[1],
                TOKENS_PER_WK: 1,
                EMB_SIZE: shape[1],
                ELEMS_PER_THREAD: 4,
                ADDRESS_SPACE: GLOBAL_ADDRESS_SPACE,
            },
            canonicalize=True,
            print_ir_after=["set_thread_dependent_index_from_reduce", "expand_graph"],
            print_ir_before=["set_thread_dependent_index_from_reduce", "expand graph"],
        )
        options = set_default_run_config(options)
        test = wave_compile(options, test)

        torch.manual_seed(1)
        a = device_randn(shape, dtype=torch.float16)
        gamma = device_randn(shape[1], dtype=torch.float16)
        c = device_zeros(shape, dtype=torch.float16)
        test(a, gamma, c)
        print(test.asm)
        print(a.cpu())
        print(c.cpu())

        rms = torch.sqrt(torch.mean(a * a, dim=-1, keepdim=True))
        ref = (a / rms) * gamma
>       torch.testing.assert_close(ref, c, atol=1e-02, rtol=1e-05)
E       AssertionError: Tensor-likes are not close!
E
E       Mismatched elements: 5006 / 5120 (97.8%)
E       Greatest absolute difference: 10.4453125 at index (0, 4448) (up to 0.01 allowed)
E       Greatest relative difference: 4.23046875 at index (0, 2472) (up to 1e-05 allowed)

tests/kernel/wave/rmsnorm_test.py:106: AssertionError
=========================== short test summary info ============================
FAILED tests/kernel/wave/rmsnorm_test.py::test_rmsnorm[shape0] - AssertionErr...
============================== 1 failed in 6.27s ===============================
